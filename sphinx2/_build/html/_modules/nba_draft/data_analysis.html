<!DOCTYPE html>

<html lang="en" data-content_root="../../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>nba_draft.data_analysis &#8212; NBA_Draft 0.0.1 documentation</title>
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=d1102ebc" />
    <link rel="stylesheet" type="text/css" href="../../_static/basic.css?v=686e5160" />
    <link rel="stylesheet" type="text/css" href="../../_static/alabaster.css?v=27fed22d" />
    <script src="../../_static/documentation_options.js?v=d45e8c67"></script>
    <script src="../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
   
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <h1>Source code for nba_draft.data_analysis</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">cross_val_score</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">classification_report</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">linear_model</span>
<span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="nn">sm</span>


<div class="viewcode-block" id="knn_analysis">
<a class="viewcode-back" href="../../nba_draft.html#nba_draft.data_analysis.knn_analysis">[docs]</a>
<span class="k">def</span> <span class="nf">knn_analysis</span><span class="p">(</span><span class="n">dframe</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Perform k-Nearest Neighbors (KNN) analysis with and without college-related predictors.</span>

<span class="sd">    This function trains a k-Nearest Neighbors classifier using two different sets of feature columns:</span>
<span class="sd">    one with college-related predictors and one without. It calculates the accuracy and cross-validation </span>
<span class="sd">    score (using F1 weighted score) for both sets of features.</span>

<span class="sd">    Args:</span>
<span class="sd">        dframe (pandas.DataFrame): The input dataframe containing player data, including the target variable &#39;Pk&#39; (Draft Pick).</span>
<span class="sd">        n (int, optional): The number of neighbors to use for the KNN classifier (default is 3).</span>

<span class="sd">    Returns:</span>
<span class="sd">        list: A list containing the accuracy for both feature sets:</span>
<span class="sd">              [accuracy_without_college_predictors, accuracy_with_college_predictors].</span>

<span class="sd">    Raises:</span>
<span class="sd">        Exception: If there are fewer than 3 players at each draft position in inputted dataframe, cross validation will not be calculated.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="c1"># Define the columns to exclude for two different feature sets: </span>
    <span class="c1"># one with college-related predictors and one without</span>
    <span class="n">exclude_cols1</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Rk&#39;</span><span class="p">,</span> <span class="s1">&#39;Player&#39;</span><span class="p">,</span> <span class="s1">&#39;Tm&#39;</span><span class="p">,</span> <span class="s1">&#39;College&#39;</span><span class="p">,</span> <span class="s1">&#39;Pk&#39;</span><span class="p">,</span> <span class="s1">&#39;WinPct_College&#39;</span><span class="p">,</span> <span class="s1">&#39;SOS_College&#39;</span><span class="p">]</span>
    <span class="n">exclude_cols2</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Rk&#39;</span><span class="p">,</span> <span class="s1">&#39;Player&#39;</span><span class="p">,</span> <span class="s1">&#39;Tm&#39;</span><span class="p">,</span> <span class="s1">&#39;College&#39;</span><span class="p">,</span> <span class="s1">&#39;Pk&#39;</span><span class="p">]</span>
    <span class="n">cols</span> <span class="o">=</span> <span class="p">[</span><span class="n">exclude_cols1</span><span class="p">,</span> <span class="n">exclude_cols2</span><span class="p">]</span>

    <span class="c1"># Fill missing values in the dataframe with 0 to avoid issues during training</span>
    <span class="n">dframe</span> <span class="o">=</span> <span class="n">dframe</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="c1"># Set the target variable as &#39;Pk&#39; (Draft Pick)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">dframe</span><span class="p">[</span><span class="s2">&quot;Pk&quot;</span><span class="p">]</span>
    
    <span class="c1"># Initialize empty lists to store accuracy and cross-validation scores</span>
    <span class="n">accuracies</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># Loop over the two feature sets (with and without college-related predictors)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">cols</span><span class="p">:</span>
        <span class="c1"># Select the features by dropping the columns to be excluded</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">dframe</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">i</span><span class="p">)</span>

        <span class="c1"># Split the data into training and testing sets (90% train, 10% test)</span>
        <span class="n">x_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

        <span class="c1"># Initialize the KNN classifier with the number of neighbors specified by `n`</span>
        <span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>

        <span class="c1"># Train the KNN model on the training data</span>
        <span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

        <span class="c1"># Make predictions on the test set</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>

        <span class="c1"># Calculate the accuracy of the model on the test set</span>
        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

        <span class="c1"># Perform 3-fold cross-validation and compute the F1 weighted score</span>
        <span class="k">if</span> <span class="n">dframe</span><span class="p">[</span><span class="s1">&#39;Draft_Yr&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">-</span> <span class="n">dframe</span><span class="p">[</span><span class="s1">&#39;Draft_Yr&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">&gt;=</span> <span class="mi">3</span><span class="p">:</span>
            <span class="n">cv_score</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">knn</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;f1_weighted&#39;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Cross validation requires at least 3 athletes in each pick position. Expand range of draft years.&quot;</span><span class="p">)</span>


        <span class="c1"># Append the results (accuracy and cross-validation scores) for each feature set</span>
        <span class="n">accuracies</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accuracy</span><span class="p">)</span>
        <span class="n">scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cv_score</span><span class="p">)</span>
    
    <span class="c1"># Print the results for each feature set (with and without college predictors)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy without college predictors: </span><span class="si">{</span><span class="n">accuracies</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="se">\n</span><span class="s2">CV Score: </span><span class="si">{</span><span class="n">scores</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy with college predictors: </span><span class="si">{</span><span class="n">accuracies</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="se">\n</span><span class="s2">CV Score: </span><span class="si">{</span><span class="n">scores</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Return the accuracies for both feature sets</span>
    <span class="k">return</span> <span class="n">accuracies</span></div>





<div class="viewcode-block" id="dtree_analysis">
<a class="viewcode-back" href="../../nba_draft.html#nba_draft.data_analysis.dtree_analysis">[docs]</a>
<span class="k">def</span> <span class="nf">dtree_analysis</span><span class="p">(</span><span class="n">dframe</span><span class="p">,</span> <span class="n">depth</span><span class="o">=</span><span class="mi">15</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Perform Decision Tree analysis with and without college predictors, including cross-validation scores and classification reports.</span>

<span class="sd">    This function splits the data into two sets of features: one with college-related predictors and one without.</span>
<span class="sd">    It then trains a Decision Tree classifier on both sets, computes the accuracy, classification report, and performs cross-validation</span>
<span class="sd">    to evaluate the performance of the model with different feature sets.</span>

<span class="sd">    Args:</span>
<span class="sd">        dframe (pandas.DataFrame): The input data frame containing player data, including the target variable &#39;Pk&#39; (Draft Pick).</span>
<span class="sd">        depth (int, optional): The maximum depth of the decision tree (default is 15).</span>

<span class="sd">    Returns:</span>
<span class="sd">        list: A list containing the accuracy for both feature sets:</span>
<span class="sd">              [accuracy_without_college_predictors, accuracy_with_college_predictors].</span>

<span class="sd">    Raises:</span>
<span class="sd">        Exception: If there are fewer than 3 players at each draft position in inputted dataframe, cross validation will not be calculated.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="c1"># Define the columns to exclude for two different feature sets: one with college-related predictors and one without</span>
    <span class="n">exclude_cols1</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Rk&#39;</span><span class="p">,</span> <span class="s1">&#39;Player&#39;</span><span class="p">,</span> <span class="s1">&#39;Tm&#39;</span><span class="p">,</span> <span class="s1">&#39;College&#39;</span><span class="p">,</span> <span class="s1">&#39;Pk&#39;</span><span class="p">,</span> <span class="s1">&#39;WinPct_College&#39;</span><span class="p">,</span> <span class="s1">&#39;SOS_College&#39;</span><span class="p">]</span>
    <span class="n">exclude_cols2</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Rk&#39;</span><span class="p">,</span> <span class="s1">&#39;Player&#39;</span><span class="p">,</span> <span class="s1">&#39;Tm&#39;</span><span class="p">,</span> <span class="s1">&#39;College&#39;</span><span class="p">,</span> <span class="s1">&#39;Pk&#39;</span><span class="p">]</span>
    <span class="n">cols</span> <span class="o">=</span> <span class="p">[</span><span class="n">exclude_cols1</span><span class="p">,</span> <span class="n">exclude_cols2</span><span class="p">]</span>

    <span class="c1"># Fill missing values in the dataframe with 0</span>
    <span class="n">dframe</span> <span class="o">=</span> <span class="n">dframe</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="c1"># Set the target variable as &#39;Pk&#39; (Draft Pick)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">dframe</span><span class="p">[</span><span class="s2">&quot;Pk&quot;</span><span class="p">]</span>
    
    <span class="c1"># Initialize empty lists to store accuracy, cross-validation scores, and classification reports</span>
    <span class="n">accuracies</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">class_reps</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># Loop over the two feature sets (with and without college-related predictors)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">cols</span><span class="p">:</span>
        <span class="c1"># Select the features by dropping the columns to be excluded</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">dframe</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">i</span><span class="p">)</span>

        <span class="c1"># Split the data into training and testing sets (90% train, 10% test)</span>
        <span class="n">x_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

        <span class="c1"># Initialize the Decision Tree model with a maximum depth of `depth`</span>
        <span class="n">tree</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="n">depth</span><span class="p">)</span>

        <span class="c1"># Train the model on the training set</span>
        <span class="n">tree</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

        <span class="c1"># Make predictions on the test set</span>
        <span class="n">y_pred_tree</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>

        <span class="c1"># Calculate the accuracy score for the model</span>
        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_tree</span><span class="p">)</span>

        <span class="c1"># Generate a classification report to evaluate model performance</span>
        <span class="n">class_rep</span> <span class="o">=</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_tree</span><span class="p">,</span> <span class="n">zero_division</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Perform 3-fold cross-validation and compute the F1 weighted score</span>
        <span class="k">if</span> <span class="n">dframe</span><span class="p">[</span><span class="s1">&#39;Draft_Yr&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">-</span> <span class="n">dframe</span><span class="p">[</span><span class="s1">&#39;Draft_Yr&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">&gt;=</span> <span class="mi">3</span><span class="p">:</span>
            <span class="n">cv_score</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">tree</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;f1_weighted&#39;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Cross validation requires at least 3 athletes in each pick position. Expand range of draft years.&quot;</span><span class="p">)</span>


        <span class="c1"># Perform 3-fold cross-validation and compute the F1 weighted score</span>
        <span class="n">cv_score</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">tree</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;f1_weighted&#39;</span><span class="p">)</span>

        <span class="c1"># Store the results (accuracy, classification report, and cross-validation scores)</span>
        <span class="n">accuracies</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accuracy</span><span class="p">)</span>
        <span class="n">class_reps</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">class_rep</span><span class="p">)</span>
        <span class="n">scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cv_score</span><span class="p">)</span>
    
    <span class="c1"># Print the results for each feature set (with and without college predictors)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Without college predictors:</span><span class="se">\n</span><span class="s2">accuracy: </span><span class="si">{</span><span class="n">accuracies</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="se">\n</span><span class="s2">CV Score: </span><span class="si">{</span><span class="n">scores</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="se">\n</span><span class="s2">Classification Report: </span><span class="si">{</span><span class="n">class_reps</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;With college predictors:</span><span class="se">\n</span><span class="s2">accuracy: </span><span class="si">{</span><span class="n">accuracies</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="se">\n</span><span class="s2">CV Score: </span><span class="si">{</span><span class="n">scores</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="se">\n</span><span class="s2">Classification Report: </span><span class="si">{</span><span class="n">class_reps</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Return the accuracies of both feature sets</span>
    <span class="k">return</span> <span class="n">accuracies</span></div>





<div class="viewcode-block" id="linreg_analysis">
<a class="viewcode-back" href="../../nba_draft.html#nba_draft.data_analysis.linreg_analysis">[docs]</a>
<span class="k">def</span> <span class="nf">linreg_analysis</span><span class="p">(</span><span class="n">dframe</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Performs linear regression analysis to predict the draft pick (Pk) and provides model summaries</span>
<span class="sd">    with and without college-related predictors.</span>

<span class="sd">    This function trains a linear regression model using two different sets of predictors:</span>
<span class="sd">    1. The first feature set excludes college-related predictors such as &#39;WinPct_College&#39; and &#39;SOS_College&#39;.</span>
<span class="sd">    2. The second feature set excludes the &#39;College&#39; and &#39;Pk&#39; columns.</span>

<span class="sd">    The model summary (coefficients, p-values, R-squared, etc.) for both sets of predictors is returned.</span>

<span class="sd">    Args:</span>
<span class="sd">        dframe (pandas.DataFrame): The input data frame containing player data, including &#39;Pk&#39; and &#39;College&#39; columns.</span>

<span class="sd">    Returns:</span>
<span class="sd">        list: A list containing the OLS regression R-squared value for both feature sets:</span>
<span class="sd">              [summary_without_college_predictors, summary_with_college_predictors].</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="c1"># Define columns to exclude for two different feature sets</span>
    <span class="n">exclude_cols1</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Rk&#39;</span><span class="p">,</span> <span class="s1">&#39;Player&#39;</span><span class="p">,</span> <span class="s1">&#39;Tm&#39;</span><span class="p">,</span> <span class="s1">&#39;College&#39;</span><span class="p">,</span> <span class="s1">&#39;Pk&#39;</span><span class="p">,</span> <span class="s1">&#39;WinPct_College&#39;</span><span class="p">,</span> <span class="s1">&#39;SOS_College&#39;</span><span class="p">]</span>
    <span class="n">exclude_cols2</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Rk&#39;</span><span class="p">,</span> <span class="s1">&#39;Player&#39;</span><span class="p">,</span> <span class="s1">&#39;Tm&#39;</span><span class="p">,</span> <span class="s1">&#39;College&#39;</span><span class="p">,</span> <span class="s1">&#39;Pk&#39;</span><span class="p">]</span>
    <span class="n">cols</span> <span class="o">=</span> <span class="p">[</span><span class="n">exclude_cols1</span><span class="p">,</span> <span class="n">exclude_cols2</span><span class="p">]</span>

    <span class="c1"># Fill missing values in the dataframe with 0</span>
    <span class="n">dframe</span> <span class="o">=</span> <span class="n">dframe</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="c1"># Set the target variable as &#39;Pk&#39; (Draft Pick)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">dframe</span><span class="p">[</span><span class="s2">&quot;Pk&quot;</span><span class="p">]</span>
    
    <span class="c1"># Initialize an empty list to store model summaries for each feature set</span>
    <span class="n">summaries</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># Loop over the two feature sets</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">cols</span><span class="p">:</span>
        
        <span class="c1"># Select the feature set by dropping the columns to be excluded</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">dframe</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">i</span><span class="p">)</span>

        <span class="c1"># Add an intercept (constant) to the model</span>
        <span class="n">x_with_intercept</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="c1"># Fit the OLS model using statsmodels</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">x_with_intercept</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

        <span class="c1"># Get the model summary (coefficients, R-squared, p-values, etc.)</span>
        <span class="n">mod_summary</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">rsquared</span>

        <span class="c1"># Append the summary to the list</span>
        <span class="n">summaries</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mod_summary</span><span class="p">)</span>

    <span class="c1"># # Print the summary for both feature sets</span>
    <span class="c1"># print(f&quot;Summary without college predictors: {summaries[0]}&quot;)</span>
    <span class="c1"># print(f&quot;Summary with college predictors: {summaries[1]}&quot;)</span>

    <span class="c1"># Return the list of model summaries</span>
    <span class="k">return</span> <span class="n">summaries</span></div>

</pre></div>

          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../index.html">NBA_Draft</a></h1>









<search id="searchbox" style="display: none" role="search">
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" placeholder="Search"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script><h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../modules.html">nba_draft</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nba_draft.html">nba_draft package</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../index.html">Documentation overview</a><ul>
  <li><a href="../index.html">Module code</a><ul>
  </ul></li>
  </ul></li>
</ul>
</div>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;2024, Josh Bergstrom, Morgan Kurth.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 8.1.3</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 1.0.0</a>
      
    </div>

    

    
  </body>
</html>